{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install diffusers transformers hf_transfer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:14:31.880858Z","iopub.execute_input":"2025-04-10T21:14:31.881832Z","iopub.status.idle":"2025-04-10T21:14:37.009136Z","shell.execute_reply.started":"2025-04-10T21:14:31.881798Z","shell.execute_reply":"2025-04-10T21:14:37.008346Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (0.1.9)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\nRequirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.30.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers) (2.4.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->diffusers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->diffusers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->diffusers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->diffusers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->diffusers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install accelerate==0.33.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:14:37.010637Z","iopub.execute_input":"2025-04-10T21:14:37.010889Z","iopub.status.idle":"2025-04-10T21:16:03.955010Z","shell.execute_reply.started":"2025-04-10T21:14:37.010867Z","shell.execute_reply":"2025-04-10T21:16:03.954319Z"}},"outputs":[{"name":"stdout","text":"Collecting accelerate==0.33.0\n  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (2.5.1+cu124)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (0.30.2)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (0.5.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (2025.3.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.17->accelerate==0.33.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.17->accelerate==0.33.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.17->accelerate==0.33.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.17->accelerate==0.33.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.17->accelerate==0.33.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.17->accelerate==0.33.0) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.33.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate==0.33.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate==0.33.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate==0.33.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate==0.33.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate==0.33.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.33.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.33.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.33.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.17->accelerate==0.33.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.17->accelerate==0.33.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.17->accelerate==0.33.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0,>=1.17->accelerate==0.33.0) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0,>=1.17->accelerate==0.33.0) (2024.2.0)\nDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.3.0\n    Uninstalling accelerate-1.3.0:\n      Successfully uninstalled accelerate-1.3.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.33.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nos.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:16:03.955843Z","iopub.execute_input":"2025-04-10T21:16:03.956038Z","iopub.status.idle":"2025-04-10T21:16:03.960344Z","shell.execute_reply.started":"2025-04-10T21:16:03.956018Z","shell.execute_reply":"2025-04-10T21:16:03.959739Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom diffusers import AutoencoderKLCogVideoX, CogVideoXPipeline, CogVideoXTransformer3DModel\nfrom diffusers.utils import export_to_video\nfrom transformers import T5EncoderModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:16:03.961179Z","iopub.execute_input":"2025-04-10T21:16:03.962012Z","iopub.status.idle":"2025-04-10T21:16:37.910294Z","shell.execute_reply.started":"2025-04-10T21:16:03.961983Z","shell.execute_reply":"2025-04-10T21:16:37.909504Z"}},"outputs":[{"name":"stderr","text":"2025-04-10 21:16:17.200969: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744319777.633318      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744319777.744513      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Models: \"THUDM/CogVideoX-2b\" or \"THUDM/CogVideoX-5b\"\nmodel_id = \"THUDM/CogVideoX-5b\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:16:37.911970Z","iopub.execute_input":"2025-04-10T21:16:37.912431Z","iopub.status.idle":"2025-04-10T21:16:37.915584Z","shell.execute_reply.started":"2025-04-10T21:16:37.912412Z","shell.execute_reply":"2025-04-10T21:16:37.914829Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"transformer = CogVideoXTransformer3DModel.from_pretrained(\"camenduru/cogvideox-5b-float16\", subfolder=\"transformer\", torch_dtype=torch.float16)\ntext_encoder = T5EncoderModel.from_pretrained(\"camenduru/cogvideox-5b-float16\", subfolder=\"text_encoder\", torch_dtype=torch.float16)\nvae = AutoencoderKLCogVideoX.from_pretrained(model_id, subfolder=\"vae\", torch_dtype=torch.float16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:16:37.916391Z","iopub.execute_input":"2025-04-10T21:16:37.916697Z","iopub.status.idle":"2025-04-10T21:18:00.237718Z","shell.execute_reply.started":"2025-04-10T21:16:37.916672Z","shell.execute_reply":"2025-04-10T21:18:00.236730Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/798 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27f657c30fd54eab93f9e90768ec2693"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ion_pytorch_model.safetensors.index.json:   0%|          | 0.00/103k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b90d01a8c54c8c86a6f442da92242c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)pytorch_model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5080484931124f3ba206ab9ef8aff13e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)pytorch_model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"622cfb0dd67f4b1e8d1bf000f368ed8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)pytorch_model-00003-of-00003.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91de651f73194ee2905efb7d6f3220d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/791 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c03a231acfe40fc908f8d04f72c810f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/19.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b2ee758792484e8333f850b9ac99e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a8fbb06655441b8ef4c6bf22329f63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c13a364ab5e64750a696aa4cc6ad9e5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/1.58G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f69916bcae7a4b5691f32195fc3a4d18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f71b82b95284c87a00e2014e3ba6959"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/872 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64e4a0c017354ec281fd8d3a544260f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/862M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aba386d64c54ac59c28c83546a7057d"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"pipe = CogVideoXPipeline.from_pretrained(\n    model_id,\n    text_encoder=text_encoder,\n    transformer=transformer,\n    vae=vae,\n    torch_dtype=torch.float16,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:18:00.238788Z","iopub.execute_input":"2025-04-10T21:18:00.239094Z","iopub.status.idle":"2025-04-10T21:18:06.170836Z","shell.execute_reply.started":"2025-04-10T21:18:00.239069Z","shell.execute_reply":"2025-04-10T21:18:06.169969Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f949bf4955c2453eb90c8ab8225cba25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"011ae5fa2bec40d0b28c17ea0f11cfe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb105184e1741ce8d85f9e4c065a236"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f1ba09eac2743b785c1f481b7344c6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96a78492cca74e9db1069b5dcdc2e873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab7b389da3742d1982a21f333185010"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5a780905b2947e595fb501ce70177c4"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"pipe.enable_sequential_cpu_offload()\n# pipe.vae.enable_tiling()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:18:06.171791Z","iopub.execute_input":"2025-04-10T21:18:06.172052Z","iopub.status.idle":"2025-04-10T21:18:06.413186Z","shell.execute_reply.started":"2025-04-10T21:18:06.172029Z","shell.execute_reply":"2025-04-10T21:18:06.412647Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"prompt = (\n    \"An electron, glowing with a faint blue hue, orbits serenely around a shimmering atomic nucleus in a vast quantum field.\"\n\"The electron emits subtle pulses of energy, creating soft, rhythmic waves that ripple through the surrounding space. Nearby, other subatomic particles gather, drawn in by the electron's mesmerizing oscillations, some resonating in sync.\"\n\"Streams of radiant energy flow like currents through the field, casting an ethereal glow that dances across the quantum landscape. The electron's motion is elegant and deliberate, reflecting both precision and harmony.\"\n\"The background shimmers with probability clouds and vibrant bursts of light, enhancing the mysterious and almost magical nature of this atomic ballet.\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:18:06.413841Z","iopub.execute_input":"2025-04-10T21:18:06.414092Z","iopub.status.idle":"2025-04-10T21:18:07.000130Z","shell.execute_reply.started":"2025-04-10T21:18:06.414076Z","shell.execute_reply":"2025-04-10T21:18:06.999305Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"video = pipe(prompt=prompt, guidance_scale=6, use_dynamic_cfg=True, num_inference_steps=5).frames[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:18:07.000947Z","iopub.execute_input":"2025-04-10T21:18:07.001170Z","iopub.status.idle":"2025-04-10T21:23:36.986253Z","shell.execute_reply.started":"2025-04-10T21:18:07.001145Z","shell.execute_reply":"2025-04-10T21:23:36.985143Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cc5bbe37e404d0b86245d668655662e"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2370416595.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_dynamic_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/cogvideo/pipeline_cogvideox.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, negative_prompt, height, width, num_frames, num_inference_steps, timesteps, guidance_scale, use_dynamic_cfg, num_videos_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, output_type, return_dict, attention_kwargs, callback_on_step_end, callback_on_step_end_tensor_inputs, max_sequence_length)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# Discard any padding frames that were added for CogVideoX 1.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_latents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/cogvideo/pipeline_cogvideox.py\u001b[0m in \u001b[0;36mdecode_latents\u001b[0;34m(self, latents)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae_scaling_factor_image\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/utils/accelerate_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_hf_hook\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pre_forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z, return_dict)\u001b[0m\n\u001b[1;32m   1285\u001b[0m             \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_slices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m             \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, z, return_dict)\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_quant_conv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m                 \u001b[0mz_intermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_quant_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_intermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m             \u001b[0mz_intermediate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_intermediate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_intermediate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sample, temb, conv_cache)\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mconv_cache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"up_block_{i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                 hidden_states, new_conv_cache[conv_cache_key] = up_block(\n\u001b[0m\u001b[1;32m    979\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_cache_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, temb, zq, conv_cache)\u001b[0m\n\u001b[1;32m    653\u001b[0m                 )\n\u001b[1;32m    654\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 hidden_states, new_conv_cache[conv_cache_key] = resnet(\n\u001b[0m\u001b[1;32m    656\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_cache_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, temb, zq, conv_cache)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mzq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_conv_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"norm2\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"norm2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, f, zq, conv_cache)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mnorm_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mnew_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_f\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconv_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconv_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_conv_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 182.12 MiB is free. Process 2356 has 14.56 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 308.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 182.12 MiB is free. Process 2356 has 14.56 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 308.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":10},{"cell_type":"code","source":"export_to_video(video, \"output.mp4\", fps=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:23:36.986930Z","iopub.status.idle":"2025-04-10T21:23:36.987281Z","shell.execute_reply.started":"2025-04-10T21:23:36.987132Z","shell.execute_reply":"2025-04-10T21:23:36.987149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport nltk\nimport numpy as np\nimport os\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nfrom diffusers.utils import export_to_video\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T00:09:05.449185Z","iopub.execute_input":"2025-04-11T00:09:05.449461Z","iopub.status.idle":"2025-04-11T00:09:05.453698Z","shell.execute_reply.started":"2025-04-11T00:09:05.449443Z","shell.execute_reply":"2025-04-11T00:09:05.452968Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T00:09:11.491611Z","iopub.execute_input":"2025-04-11T00:09:11.491895Z","iopub.status.idle":"2025-04-11T00:10:18.907937Z","shell.execute_reply.started":"2025-04-11T00:09:11.491875Z","shell.execute_reply":"2025-04-11T00:10:18.907273Z"}},"outputs":[{"name":"stdout","text":"Loading pipeline...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/496 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be34b3ac47d54287996d233ac052942e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db0a2e3439d4ae9ae4f5838c3d095c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a9c131a79b249c9b20ba0ba079fbedc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5405e70f09d44648839eb73ab56c7d6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/518 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"536cfca4fc2e41ea8060f36ca6fcb5d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/984 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc0dd7f9ca3446bb8dd234b40fb2ba1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/607 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc0da843af274e90b2d7ac8c957551ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/391M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4641e1c6f79843b29bff026cc12345ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45846b9d402e44c48c272aab178252ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/6.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59c3d83694734e1391ff6523cea57062"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c89c4f68d6304622bd32a1bfcf87be2d"}},"metadata":{}},{"name":"stdout","text":"['The Pythagorean Theorem is one of the fundamental principles in geometry.', 'It describes a relationship between the sides of a right triangle.', 'A right triangle is a triangle that contains a 90-degree angle.', 'In this theorem, the three sides of the triangle are referred to as the two legs and the hypotenuse.', 'The two legs are the sides that form the right angle, while the hypotenuse is the longest side, opposite the right angle.', 'The Pythagorean Theorem states that the square of the length of the hypotenuse is equal to the sum of the squares of the lengths of the other two sides.', 'Mathematically, this is expressed as: a² + b² = c² Here, a and b represent the lengths of the two legs, and c represents the length of the hypotenuse.', 'This theorem only applies to right triangles.', 'If a triangle does not have a right angle, the Pythagorean Theorem does not apply.', 'To visualize this, imagine a right triangle with a square drawn on each of its sides.', 'The area of the square on the hypotenuse will equal the combined area of the squares on the other two sides.', 'This is the essence of the Pythagorean Theorem.', 'The Pythagorean Theorem was named after the ancient Greek mathematician Pythagoras.', 'However, the knowledge of this relationship predates Pythagoras, with evidence suggesting that ancient civilizations such as the Babylonians and Egyptians were aware of the principle.', 'Pythagoras, however, is credited with being the first to formally prove it.', 'Over time, the theorem became a cornerstone of Euclidean geometry.', 'In practical terms, the Pythagorean Theorem is incredibly useful.', 'It helps in calculating distances, heights, and angles in various fields such as engineering, architecture, astronomy, and navigation.', 'For example, if you know the lengths of the legs of a right triangle, you can easily find the length of the hypotenuse by applying the Pythagorean Theorem.', 'Conversely, if you know the hypotenuse and one leg, you can find the missing leg.', 'Let’s consider a simple example: imagine a right triangle where one leg is 3 units long and the other leg is 4 units long.', 'To find the length of the hypotenuse, you can apply the Pythagorean Theorem: a² + b² = c² 3² + 4² = c² 9 + 16 = c² 25 = c² Taking the square root of both sides: √25 = c So, c = 5.', 'Therefore, the hypotenuse of this right triangle is 5 units long.', 'This is a practical demonstration of the Pythagorean Theorem in action.', 'The theorem is not limited to simple integer values, though.', 'It applies to all right triangles, regardless of the specific lengths of the sides, as long as the triangle remains a right triangle.', 'Another example might be a triangle with legs of 5 and 12 units.', 'Using the same steps: 5² + 12² = c² 25 + 144 = c² 169 = c² √169 = c c = 13.', 'Thus, the hypotenuse in this case would be 13 units long.', 'The Pythagorean Theorem is also helpful in real-world applications, such as finding the distance between two points on a coordinate plane.', 'Suppose you need to calculate the straight-line distance between two points, (x₁, y₁) and (x₂, y₂), on a grid.', 'The horizontal distance between the points is |x₂ - x₁| and the vertical distance is |y₂ - y₁|.', 'These can be treated as the two legs of a right triangle, and the distance between the points is the hypotenuse.', 'The formula in this case becomes: Distance = √[(x₂ - x₁)² + (y₂ - y₁)²] This is directly derived from the Pythagorean Theorem.', 'While the Pythagorean Theorem is a powerful tool, there are some important points to consider.', 'First, it only applies to right triangles.', 'Second, the theorem involves squares and square roots, so it requires a basic understanding of algebra to use effectively.', 'Fortunately, with practice, these concepts become easier to apply.', 'Additionally, the Pythagorean Theorem is a foundational principle in trigonometry, where it’s used to define other relationships, such as the sine, cosine, and tangent functions.', 'These functions help describe angles and sides in right triangles and are used extensively in various scientific and engineering disciplines.', 'The Pythagorean Theorem also leads to interesting properties and extensions.', 'For instance, in three-dimensional space, there is a generalized version of the theorem called the distance formula, which applies to right-angled triangles in 3D geometry.', 'In this case, the formula is: Distance = √[(x₂ - x₁)² + (y₂ - y₁)² + (z₂ - z₁)²] Moreover, the Pythagorean Theorem has inspired countless mathematical discoveries and theorems.', 'One notable result is the Pythagorean triple, where the lengths of the three sides of a right triangle are all integers.', 'An example of a Pythagorean triple is the set {3, 4, 5}, where 3² + 4² = 5².', 'Another interesting extension of the Pythagorean Theorem is the concept of irrational numbers.', 'In some cases, the length of the hypotenuse of a right triangle is not an integer, but an irrational number, such as the square root of 2.', 'This was discovered by ancient Greek mathematicians and marked a major shift in the understanding of numbers.', 'In summary, the Pythagorean Theorem is one of the most important principles in mathematics.', 'It provides a simple yet powerful way to relate the sides of a right triangle.', 'From ancient times to modern applications, the Pythagorean Theorem has been essential in solving practical problems.', 'Its impact extends beyond geometry into various fields like physics, engineering, and computer science.', 'Understanding this theorem is not only important for students learning geometry but also for anyone seeking to understand the world of mathematical relationships and spatial reasoning.']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T00:10:26.834353Z","iopub.execute_input":"2025-04-11T00:10:26.834928Z","iopub.status.idle":"2025-04-11T00:10:26.841713Z","shell.execute_reply.started":"2025-04-11T00:10:26.834909Z","shell.execute_reply":"2025-04-11T00:10:26.841095Z"}},"outputs":[{"name":"stdout","text":"['The Pythagorean Theorem is one of the fundamental principles in geometry.', 'It describes a relationship between the sides of a right triangle.', 'A right triangle is a triangle that contains a 90-degree angle.', 'In this theorem, the three sides of the triangle are referred to as the two legs and the hypotenuse.', 'The two legs are the sides that form the right angle, while the hypotenuse is the longest side, opposite the right angle.', 'The Pythagorean Theorem states that the square of the length of the hypotenuse is equal to the sum of the squares of the lengths of the other two sides.', 'Mathematically, this is expressed as: a² + b² = c² Here, a and b represent the lengths of the two legs, and c represents the length of the hypotenuse.', 'This theorem only applies to right triangles.', 'If a triangle does not have a right angle, the Pythagorean Theorem does not apply.', 'To visualize this, imagine a right triangle with a square drawn on each of its sides.', 'The area of the square on the hypotenuse will equal the combined area of the squares on the other two sides.', 'This is the essence of the Pythagorean Theorem.', 'The Pythagorean Theorem was named after the ancient Greek mathematician Pythagoras.', 'However, the knowledge of this relationship predates Pythagoras, with evidence suggesting that ancient civilizations such as the Babylonians and Egyptians were aware of the principle.', 'Pythagoras, however, is credited with being the first to formally prove it.', 'Over time, the theorem became a cornerstone of Euclidean geometry.', 'In practical terms, the Pythagorean Theorem is incredibly useful.', 'It helps in calculating distances, heights, and angles in various fields such as engineering, architecture, astronomy, and navigation.', 'For example, if you know the lengths of the legs of a right triangle, you can easily find the length of the hypotenuse by applying the Pythagorean Theorem.', 'Conversely, if you know the hypotenuse and one leg, you can find the missing leg.', 'Let’s consider a simple example: imagine a right triangle where one leg is 3 units long and the other leg is 4 units long.', 'To find the length of the hypotenuse, you can apply the Pythagorean Theorem: a² + b² = c² 3² + 4² = c² 9 + 16 = c² 25 = c² Taking the square root of both sides: √25 = c So, c = 5.', 'Therefore, the hypotenuse of this right triangle is 5 units long.', 'This is a practical demonstration of the Pythagorean Theorem in action.', 'The theorem is not limited to simple integer values, though.', 'It applies to all right triangles, regardless of the specific lengths of the sides, as long as the triangle remains a right triangle.', 'Another example might be a triangle with legs of 5 and 12 units.', 'Using the same steps: 5² + 12² = c² 25 + 144 = c² 169 = c² √169 = c c = 13.', 'Thus, the hypotenuse in this case would be 13 units long.', 'The Pythagorean Theorem is also helpful in real-world applications, such as finding the distance between two points on a coordinate plane.']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\nimport nltk\nimport numpy as np\nimport os\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nfrom diffusers.utils import export_to_video\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm\n\n# Initialize NLTK for text processing\ntry:\n    nltk.data.find('tokenizers/punkt')\nexcept LookupError:\n    nltk.download('punkt')\n\n# Set device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load the pipeline\nprint(\"Loading pipeline...\")\npipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-video-diffusion-img2vid-xt\", torch_dtype=torch.float16)\npipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\npipe = pipe.to(device)\n\n# Original prompt\nprompt = \"\"\"\nThe Pythagorean Theorem is one of the fundamental principles in geometry. It describes a relationship between the sides of a right triangle. A right triangle is a triangle that contains a 90-degree angle. In this theorem, the three sides of the triangle are referred to as the two legs and the hypotenuse. The two legs are the sides that form the right angle, while the hypotenuse is the longest side, opposite the right angle. The Pythagorean Theorem states that the square of the length of the hypotenuse is equal to the sum of the squares of the lengths of the other two sides.\n\nMathematically, this is expressed as:\na² + b² = c²\n\nHere, a and b represent the lengths of the two legs, and c represents the length of the hypotenuse. This theorem only applies to right triangles. If a triangle does not have a right angle, the Pythagorean Theorem does not apply. To visualize this, imagine a right triangle with a square drawn on each of its sides. The area of the square on the hypotenuse will equal the combined area of the squares on the other two sides. This is the essence of the Pythagorean Theorem.\n\nThe Pythagorean Theorem was named after the ancient Greek mathematician Pythagoras. However, the knowledge of this relationship predates Pythagoras, with evidence suggesting that ancient civilizations such as the Babylonians and Egyptians were aware of the principle. Pythagoras, however, is credited with being the first to formally prove it. Over time, the theorem became a cornerstone of Euclidean geometry.\n\nIn practical terms, the Pythagorean Theorem is incredibly useful. It helps in calculating distances, heights, and angles in various fields such as engineering, architecture, astronomy, and navigation. For example, if you know the lengths of the legs of a right triangle, you can easily find the length of the hypotenuse by applying the Pythagorean Theorem. Conversely, if you know the hypotenuse and one leg, you can find the missing leg.\n\nLet’s consider a simple example: imagine a right triangle where one leg is 3 units long and the other leg is 4 units long. To find the length of the hypotenuse, you can apply the Pythagorean Theorem:\na² + b² = c²\n3² + 4² = c²\n9 + 16 = c²\n25 = c²\nTaking the square root of both sides:\n√25 = c\nSo, c = 5.\nTherefore, the hypotenuse of this right triangle is 5 units long.\n\nThis is a practical demonstration of the Pythagorean Theorem in action. The theorem is not limited to simple integer values, though. It applies to all right triangles, regardless of the specific lengths of the sides, as long as the triangle remains a right triangle. Another example might be a triangle with legs of 5 and 12 units. Using the same steps:\n5² + 12² = c²\n25 + 144 = c²\n169 = c²\n√169 = c\nc = 13.\nThus, the hypotenuse in this case would be 13 units long.\n\nThe Pythagorean Theorem is also helpful in real-world applications, such as finding the distance between two points on a coordinate plane. Suppose you need to calculate the straight-line distance between two points, (x₁, y₁) and (x₂, y₂), on a grid. The horizontal distance between the points is |x₂ - x₁| and the vertical distance is |y₂ - y₁|. These can be treated as the two legs of a right triangle, and the distance between the points is the hypotenuse. The formula in this case becomes:\nDistance = √[(x₂ - x₁)² + (y₂ - y₁)²]\nThis is directly derived from the Pythagorean Theorem.\n\nWhile the Pythagorean Theorem is a powerful tool, there are some important points to consider. First, it only applies to right triangles. Second, the theorem involves squares and square roots, so it requires a basic understanding of algebra to use effectively. Fortunately, with practice, these concepts become easier to apply.\n\nAdditionally, the Pythagorean Theorem is a foundational principle in trigonometry, where it’s used to define other relationships, such as the sine, cosine, and tangent functions. These functions help describe angles and sides in right triangles and are used extensively in various scientific and engineering disciplines.\n\nThe Pythagorean Theorem also leads to interesting properties and extensions. For instance, in three-dimensional space, there is a generalized version of the theorem called the distance formula, which applies to right-angled triangles in 3D geometry. In this case, the formula is:\nDistance = √[(x₂ - x₁)² + (y₂ - y₁)² + (z₂ - z₁)²]\n\nMoreover, the Pythagorean Theorem has inspired countless mathematical discoveries and theorems. One notable result is the Pythagorean triple, where the lengths of the three sides of a right triangle are all integers. An example of a Pythagorean triple is the set {3, 4, 5}, where 3² + 4² = 5².\n\nAnother interesting extension of the Pythagorean Theorem is the concept of irrational numbers. In some cases, the length of the hypotenuse of a right triangle is not an integer, but an irrational number, such as the square root of 2. This was discovered by ancient Greek mathematicians and marked a major shift in the understanding of numbers.\n\nIn summary, the Pythagorean Theorem is one of the most important principles in mathematics. It provides a simple yet powerful way to relate the sides of a right triangle. From ancient times to modern applications, the Pythagorean Theorem has been essential in solving practical problems. Its impact extends beyond geometry into various fields like physics, engineering, and computer science. Understanding this theorem is not only important for students learning geometry but also for anyone seeking to understand the world of mathematical relationships and spatial reasoning.\n\"\"\"\n\n# Clean the prompt - remove extra whitespace and line breaks\nclean_prompt = ' '.join(prompt.split())\n\n# Break the prompt into sentences\nsentences = nltk.sent_tokenize(clean_prompt)\nprint(sentences)\n\n# If we have fewer than 30 sentences, we'll repeat or interpolate\nif len(sentences) < 30:\n    # Create interpolated prompts between sentences\n    expanded_prompts = []\n    for i in range(len(sentences)-1):\n        current = sentences[i]\n        next_sent = sentences[i+1]\n        \n        # Add the current sentence\n        expanded_prompts.append(current)\n        \n        # If we need more granularity, interpolate between sentences\n        if len(sentences) < 15:  # If very few sentences, add intermediate steps\n            expanded_prompts.append(f\"{current} {next_sent}\")\n    \n    # Add the final sentence\n    expanded_prompts.append(sentences[-1])\n    \n    # If we still need more, duplicate with slight variations\n    if len(expanded_prompts) < 30:\n        final_prompts = []\n        repeat_factor = max(1, 30 // len(expanded_prompts))\n        \n        for prompt in expanded_prompts:\n            for i in range(repeat_factor):\n                if i == 0:\n                    final_prompts.append(prompt)\n                else:\n                    # Add small variations for repeated prompts\n                    intensity = [\"gradually\", \"slowly\", \"steadily\", \"continually\"][i % 4]\n                    final_prompts.append(f\"{intensity} {prompt}\")\n        \n        # Take the first 30 or pad if needed\n        if len(final_prompts) > 30:\n            prompts = final_prompts[:30]\n        else:\n            # Pad with repeats of the last sentence if needed\n            padding = 30 - len(final_prompts)\n            prompts = final_prompts + [sentences[-1]] * padding\n    else:\n        prompts = expanded_prompts[:30]\nelse:\n    # If we have enough sentences, take the first 30\n    prompts = sentences[:30]\n\nprint(prompts)\n\nprint(f\"Created {len(prompts)} sequential prompts\")\n\n# Parameters\nnum_frames_per_segment = 8  # Standard 8 frames per segment\nfps = 8  # Standard fps\nnum_inference_steps = 10  # Quality setting\n\n# Create temporary directory for frames\nos.makedirs(\"temp_frames\", exist_ok=True)\n\n# Generate segments sequentially\nall_frames = []\nlast_frame = None\n\nprint(\"Generating video segments:\")\nfor i, segment_prompt in enumerate(tqdm(prompts)):\n    print(f\"\\nSegment {i+1}/30: {segment_prompt[:50]}...\")\n    \n    # Generate current segment\n    with torch.no_grad():\n        if last_frame is not None:\n            # Use the last frame as conditioning (not all models support this)\n            try:\n                video_frames = pipe(\n                    segment_prompt, \n                    num_inference_steps=num_inference_steps,\n                    num_frames=num_frames_per_segment,\n                    # Some models support conditioning with an image\n                    # If your model doesn't support this, remove the next line\n                    # image=last_frame\n                ).frames\n            except Exception as e:\n                print(f\"Image conditioning failed: {e}\")\n                # Fallback without image conditioning\n                video_frames = pipe(\n                    segment_prompt, \n                    num_inference_steps=num_inference_steps,\n                    num_frames=num_frames_per_segment\n                ).frames\n        else:\n            # First segment without conditioning\n            video_frames = pipe(\n                segment_prompt, \n                num_inference_steps=num_inference_steps,\n                num_frames=num_frames_per_segment\n            ).frames\n    \n    # Make sure we have the right format\n    if len(video_frames.shape) == 5:  # If shape is [batch, frames, height, width, channels]\n        video_frames = video_frames[0]  # Take the first batch\n    \n    # Store the last frame for next iteration\n    last_frame = video_frames[-1]  # Last frame for continuation\n    \n    # Add to our collection\n    all_frames.extend(video_frames)\n    \n    # Clear GPU memory\n    torch.cuda.empty_cache()\n\n# Convert frames to proper format for export\nall_frames = torch.stack(all_frames) if isinstance(all_frames[0], torch.Tensor) else np.array(all_frames)\n\n# Save the final video\noutput_path = \"p_30sec.mp4\"\nexport_to_video(all_frames, output_path, fps=fps)\nprint(f\"Video saved to: {output_path}\")\n\n# Clean up\nimport shutil\nif os.path.exists(\"temp_frames\"):\n    shutil.rmtree(\"temp_frames\")\n\n# Display information about the generated video\nprint(f\"Generated video details:\")\nprint(f\"- Duration: {len(all_frames)/fps:.2f} seconds\")\nprint(f\"- Frames: {len(all_frames)}\")\nprint(f\"- FPS: {fps}\")\nprint(f\"- Resolution: {all_frames[0].shape[0]}x{all_frames[0].shape[1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T00:11:37.483276Z","iopub.execute_input":"2025-04-11T00:11:37.483553Z","iopub.status.idle":"2025-04-11T00:11:40.556985Z","shell.execute_reply.started":"2025-04-11T00:11:37.483533Z","shell.execute_reply":"2025-04-11T00:11:40.555945Z"}},"outputs":[{"name":"stdout","text":"Loading pipeline...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9905d5a4c5034efaa1a7315225e0bba9"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2211290642.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading pipeline...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiffusionPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stabilityai/stable-video-diffusion-img2vid-xt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPMSolverMultistepScheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;31m# load sub model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                 loaded_sub_model = load_sub_model(\n\u001b[0m\u001b[1;32m    925\u001b[0m                     \u001b[0mlibrary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrary_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                     \u001b[0mclass_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/pipeline_loading_utils.py\u001b[0m in \u001b[0;36mload_sub_model\u001b[0;34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder, use_safetensors)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;31m# check if the module is in a subdirectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mloaded_sub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloading_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# else load from the root directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"import torch\nimport nltk\nimport numpy as np\nimport os\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler, StableVideoDiffusionPipeline\nfrom diffusers.utils import export_to_video\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm\nimport gc\n\n# Set environment variable to help with memory allocation\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\n# Initialize NLTK for text processing\ntry:\n    nltk.data.find('tokenizers/punkt')\nexcept LookupError:\n    nltk.download('punkt')\n\n# Set device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Function to clear GPU memory\ndef clear_gpu_memory():\n    gc.collect()\n    torch.cuda.empty_cache()\n    if torch.cuda.is_available():\n        torch.cuda.synchronize()\n\n# Create a list of visual prompts for the Pythagorean theorem\nvisual_prompts = [\n    \"A right triangle with squares drawn on each side, demonstrating the Pythagorean theorem, simple diagram\",\n    \"A visual representation of a² + b² = c², geometric demonstration\",\n    \"Ancient Greek mathematician Pythagoras teaching geometry\",\n    \"Mathematical diagram showing the Pythagorean theorem\",\n    \"A right triangle with sides 3, 4, and 5 units\",\n    \"Step-by-step calculation showing 3² + 4² = 5²\",\n    \"A right triangle with sides 5, 12, and 13\",\n    \"Coordinate plane showing distance calculation using Pythagorean theorem\",\n    \"Visual representation of the distance formula\",\n    \"Mathematical diagram of right triangles\",\n    \"Trigonometric functions using right triangles\",\n    \"3D visualization of the Pythagorean theorem\",\n    \"Visual explanation of the distance formula in 3D space\",\n    \"Pythagorean triples displayed as right triangles\",\n    \"Visual proof using a right triangle with unit sides\",\n    \"Development of the Pythagorean theorem across civilizations\",\n    \"Applications of the Pythagorean theorem in architecture\",\n    \"Students learning the Pythagorean theorem\",\n    \"Computer graphics showing Pythagorean calculations\",\n    \"Engineering applications of the Pythagorean theorem\",\n]\n\n# Ensure we have enough visual prompts\nwhile len(visual_prompts) < 30:\n    visual_prompts.extend(visual_prompts[:30-len(visual_prompts)])\n\n# Take the first 30 visual prompts\nvisual_prompts = visual_prompts[:30]\n\nprint(f\"Created {len(visual_prompts)} visual prompts for video generation\")\n\n# Parameters for video generation - reduced for memory efficiency\nnum_frames_per_segment = 4  # Reduced from 8 to 4\nfps = 8\nnum_inference_steps = 20  # Reduced from 25\nheight = 384  # Reduced from 512\nwidth = 384   # Reduced from 512\n\n# Create output directory for frames\nos.makedirs(\"output_frames\", exist_ok=True)\n\n# Memory-efficient approach: Generate one segment at a time and save frames\nall_frame_paths = []\nsegment_count = 0\n\nprint(\"Generating segments one by one...\")\n\ntry:\n    # Load text-to-image model first\n    print(\"Loading text-to-image pipeline...\")\n    t2i_pipe = DiffusionPipeline.from_pretrained(\n        \"runwayml/stable-diffusion-v1-5\", \n        torch_dtype=torch.float16,\n        variant=\"fp16\",\n        use_safetensors=True\n    )\n    t2i_pipe = t2i_pipe.to(device)\n    \n    # Generate the initial image\n    print(\"Generating initial image...\")\n    init_image = t2i_pipe(\n        prompt=visual_prompts[0],\n        height=height,\n        width=width,\n        num_inference_steps=20  # Reduced for memory\n    ).images[0]\n    \n    # Save the initial image\n    init_image.save(\"initial_frame.jpg\")\n    \n    # Unload the text-to-image model to free memory\n    del t2i_pipe\n    clear_gpu_memory()\n    \n    # Load image-to-video model\n    print(\"Loading image-to-video pipeline...\")\n    i2v_pipe = StableVideoDiffusionPipeline.from_pretrained(\n        \"stabilityai/stable-video-diffusion-img2vid-xt\", \n        torch_dtype=torch.float16,\n        variant=\"fp16\",\n        use_safetensors=True\n    )\n    i2v_pipe.enable_model_cpu_offload()  # Enable CPU offloading to save GPU memory\n    \n    # Start with the initial image\n    current_image = init_image\n    \n    # Process each segment\n    for i, visual_prompt in enumerate(visual_prompts):\n        print(f\"\\nSegment {i+1}/{len(visual_prompts)}: {visual_prompt[:50]}...\")\n        \n        # Set seed for consistent but progressive generation\n        generator = torch.Generator(device=device).manual_seed(42 + i)\n        \n        # Generate video segment\n        outputs = i2v_pipe(\n            image=current_image,\n            num_frames=num_frames_per_segment,\n            num_inference_steps=num_inference_steps,\n            generator=generator,\n            motion_bucket_id=min(100 + i*5, 255),  # Lower motion for memory efficiency\n            fps=fps\n        )\n        \n        # Get frames and save them individually\n        frames = outputs.frames\n        \n        # Save each frame as an image file\n        segment_frame_paths = []\n        for f_idx, frame in enumerate(frames):\n            frame_path = f\"output_frames/segment_{i+1:02d}_frame_{f_idx+1:02d}.jpg\"\n            if isinstance(frame, torch.Tensor):\n                # Convert tensor to PIL Image if needed\n                if frame.dim() == 4:  # [batch, channels, height, width]\n                    frame = frame.squeeze(0)\n                if frame.shape[0] == 3:  # [channels, height, width]\n                    frame = frame.permute(1, 2, 0)\n                if frame.max() <= 1.0:\n                    frame = (frame * 255).byte()\n                frame = Image.fromarray(frame.cpu().numpy())\n            \n            # Save the frame\n            frame.save(frame_path)\n            segment_frame_paths.append(frame_path)\n        \n        # Update current image to the last frame\n        current_image = Image.open(segment_frame_paths[-1])\n        \n        # Add frame paths to our collection\n        all_frame_paths.extend(segment_frame_paths)\n        \n        # Clear GPU memory after each segment\n        clear_gpu_memory()\n        \n        segment_count += 1\n    \n    # Unload the image-to-video model\n    del i2v_pipe\n    clear_gpu_memory()\n    \n    print(f\"Generated {segment_count} segments successfully\")\n    \n    # Now combine the saved frames into a video\n    print(\"Combining frames into video...\")\n    \n    frames_list = []\n    for frame_path in all_frame_paths:\n        img = cv2.imread(frame_path)\n        if img is not None:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n            frames_list.append(img)\n    \n    # Ensure we have frames\n    if len(frames_list) > 0:\n        frames_array = np.array(frames_list)\n        \n        # Save the final video\n        output_path = \"pythagorean_theorem_video.mp4\"\n        export_to_video(frames_array, output_path, fps=fps)\n        print(f\"Video saved to: {output_path}\")\n        \n        # Display information about the generated video\n        print(f\"Generated video details:\")\n        print(f\"- Duration: {len(frames_list)/fps:.2f} seconds\")\n        print(f\"- Frames: {len(frames_list)}\")\n        print(f\"- FPS: {fps}\")\n        print(f\"- Resolution: {frames_list[0].shape[0]}x{frames_list[0].shape[1]}\")\n    else:\n        print(\"No frames were generated or loaded.\")\n\nexcept Exception as e:\n    print(f\"Error during video generation: {e}\")\n    import traceback\n    traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T00:17:34.119403Z","iopub.execute_input":"2025-04-11T00:17:34.120120Z","iopub.status.idle":"2025-04-11T00:18:25.745137Z","shell.execute_reply.started":"2025-04-11T00:17:34.120096Z","shell.execute_reply":"2025-04-11T00:18:25.744526Z"}},"outputs":[{"name":"stdout","text":"Created 30 visual prompts for video generation\nGenerating segments one by one...\nLoading text-to-image pipeline...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11f66236fd474fb196b37cad6854104a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.fp16.safetensors:   0%|          | 0.00/608M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"771f378aae7a4601ac773cea4b529b29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ed2482744d849469815424f9655b211"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3041da7b6b7543949c11fc7099df332e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/1.72G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf2557cbd5344f07b9da2a211028eb35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe0c7c66608048c5adab13c65a0712ca"}},"metadata":{}},{"name":"stdout","text":"Generating initial image...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3c139846eed46289cf17e1052509124"}},"metadata":{}},{"name":"stdout","text":"Loading image-to-video pipeline...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7460313d15094126ac0c3196bb9b7099"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.fp16.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3063057dfdd4c98a9b9c7a64d3581d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/196M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c990423c43ef4a14b4341a4cb45db0b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/3.05G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b5902c88ba44391b2d20a505bf8a4ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf532f21de484bf68e521e731e2c7ac2"}},"metadata":{}},{"name":"stdout","text":"\nSegment 1/30: A right triangle with squares drawn on each side, ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1f7cbc44b44793b72fb7133c6d7b9b"}},"metadata":{}},{"name":"stdout","text":"Error during video generation: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 38.12 MiB is free. Process 9962 has 14.70 GiB memory in use. Of the allocated memory 14.24 GiB is allocated by PyTorch, and 342.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_31/2137607266.py\", line 128, in <cell line: 0>\n    outputs = i2v_pipe(\n              ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/stable_video_diffusion/pipeline_stable_video_diffusion.py\", line 576, in __call__\n    noise_pred = self.unet(\n                 ^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/hooks.py\", line 170, in new_forward\n    output = module._old_forward(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/unets/unet_spatio_temporal_condition.py\", line 485, in forward\n    sample = upsample_block(\n             ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/unets/unet_3d_blocks.py\", line 1529, in forward\n    hidden_states = attn(\n                    ^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/transformers/transformer_temporal.py\", line 361, in forward\n    hidden_states_mix = temporal_block(\n                        ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py\", line 758, in forward\n    ff_output = self.ff(norm_hidden_states)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py\", line 1251, in forward\n    hidden_states = module(hidden_states)\n                    ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py\", line 123, in forward\n    return hidden_states * self.gelu(gate)\n           ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 38.12 MiB is free. Process 9962 has 14.70 GiB memory in use. Of the allocated memory 14.24 GiB is allocated by PyTorch, and 342.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"}],"execution_count":17}]}